\documentclass{report}

\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{csquotes}
\usepackage[a4paper]{geometry}

\usepackage[
    backend=biber,
    style=apa,
    sortlocale=de_DE,
    natbib=true,
    url=false,
    doi=false,
    sortcites=true,
    sorting=nyt,
    isbn=false,
    hyperref=true,
    backref=false,
    giveninits=false,
    eprint=false]{biblatex}
\addbibresource{../references/bibliography.bib}


\title{Wenn die Grenzen zwischen Menschen und KI verwischen}
\author{Lucy Wehrli}
\date{\today}


\begin{document}

\maketitle

\abstract{
    Was für ethische Folgen hat es, wenn die Grenzen zwischen KI und Menschen verwischen und die Unterscheidung immer schwieriger wird?
}

\tableofcontents

\chapter{}
\section{ Einleitung}

Die Künstliche Intelligenz oder KI bzw. AI ist nun schon länger ein fester Bestandteil in unserem Alltag. In der Schule arbeiten wird damit, viele Schüler nutzen ChatGPT für die Testvorbereitung und in den Nachrichten hört man ziemlich oft davon. Man sieht vermehrt auch Videos oder Audios, die von KIs erzeugt worden sind, die man fast nicht mehr von realen Videos und Audios unterscheiden kann.
\par 
Das bringt natürlich einige Kosequenzen mit sich was Kriminalität, Sicherheit, Glaubwürdigkeit und weiter Dinge betrifft. Es können einfach Videos erstellt werden, die zum Beispiel einen Sohn imitieren, der entführt wurde und nun soll Lösegeld gezahlt werden. Doch in Wahrheit ist der Sohn gar nicht entführt und es ist nur eine Betrugsmasche, um viel Geld zu erhalten. Das stellt ganz Sicher etwas mit der Psyche des Menschen an, wenn man sich bewusst wird, was das Ganze eigentlich bedeutet. Es hat aber auch ethische Folgen und Aspekte. Dieses ganze Thema werde ich hier behandeln.




\section{Sind KIs wirklich intelligent?}
KI Tools funktionieren alle ziemlich ähnlich. Ich werde hier mit dem Beispiel von ChatGPT arbeiten. ChatGPT wurde mit einer Unmenge an Daten sozusagen "gefüttert" und kann nun aus allen Daten, die heraussuchen, die für die gestellte Frage relevant sind.
\par
Hier ist jedoch sehr wichtig zu wissen, dass ChatGPT momentan auf dem Stand von 2021 ist, da es 2021 entwickelt wurde und nur mit den bis dahin vorhanden Daten ausgestattet werden konnte. KIs haben also ein extrem grossen Datenrepertoire, dass jedoch nicht auf dem neusten Stand ist. Das heisst, dass ChatGPT zum Beispiel keine Möglichkeit hat, das Resultat eines Fussballspiels von 2023 zu wissen, da ihm ganz einfach die Daten dazu fehlen.
\par
Das wirft natürlich ein paar Fragen auf, denn das ganze wird ja Künstliche Intelligenz genannt. Eine so simple Frage sollte doch eine " intelligente" Maschine beantworten können. Sie sind also nicht intelligent, sondern lediglich extrem fähig Daten zusammenzufassen. Intelligenz ist definiert als "die kognitive bzw. geistige Leisungsfähigkeit speziell im Problemelösen. Ein Computer und somit auch KIs sind sehr gut im Probleme lösen und sie sind darin auch deutlich schneller als ein Mensch. So gelang es auch dem Programm Deep Blue den Schachweltmeister Garry Kasparov zu besiegen, weil  das rogramm schlichtweg eine Unmenge an Möglichkeiten vor jedem Zug berechnete. Hierzu war Garry Kasparov gar nicht fähig.
\par 
Doch sind KIs wirklich geistig leistungsfähig? Hierzu sagen viele Experten nein, denn KIs können nur durch hohe Rechenkraft intelligent wirken. Es ist aber sicherlich schon einigen passiert, dass sie gedacht haben, dass ChatGPT eine Frage versteht oder erklärt, oder sogar etwas denkt. Dies kann sehr schnell problematisch werden, denn so verwischen die Grenzen zwischen menschlich und künstlich extrem schnell und stark. Es ist ganz klar problematisch, wenn menschliche Züge wie Denken, Bewusstsein oder sogar Mitgefühl einer KI zugeschrieben werden. 

\section{Turing Test}

Um menschliche und künstliche Zügen trennen zu können, gibt es den sogenannten Turing Test. Dieser ist nach seinem Erfinder Alan Turing benannt. Er wurde im Jahre 1950 das erste Mal angewendet. Er funktioniert wie folgt.
\par
Ein Mensch kommuniziert mit einer KI und mit einem Menschen. Er weiss jedoch nicht wann er mit welchem der zwei Optionen kommuniziert. Wenn der Mensch nach einem gewissen Zeitraum nicht unterscheiden konnte, bei welchem Gegenüber es sich um die KI und bei welchem es sich um den Menschen handelt, gilt die Maschine als intelligent. 2014 wurde diser Test das erste Mal von einer KI bestanden. Das Ergebnis gilt jedoch als umstritten. Es ist jedoch wichtig zu wissen, dass es ChatGPT gelang, den Test zu bestehen. Es ist also laut Turing Test bereits nicht mehr möglich zwischen Menschen und ChatGPT zu unterscheiden.
\par 
Was hier auch anzumerken ist, ist dass die CAPTCHA Fragen, wo man zum Beispiel gefragt wird, alle Ampeln anzuklicken, auch auf dem Turing Test basieren. CAPTCHA bedeutet nämlich "Completely Automated Public Turing-Test to tell Computers and Humans Apart".

\section{ELIZA - Effekt}
Kommen wir nun zu dem wichtigsten Aspekt. Dem sogenannten ELIZA - Effekt. Er wurde nach einem Computerprogramm namens ELIZA benannt. Die Leute, die mit dem Programm arbeiteten begannen ihm menschliche Fähigkeiten wie Gefühle und Verständnis zuzuschreiben. Sie kommunizierten mit ihm, wie mit einem richtigen Menschen und vertrauten den Programm sogar Geheimnisse an.
\par 
Der ELIZA - Effekt steht für die Vermenschlichung von Robotern, KIs und Algorithmen. Der Mensch verliert das Bewusstsein und vergisst mehr oder weniger, dass er nicht mit einem Menschen kommunizert, sondern mit einer KI. Man beginnt der Maschine menschliche Fähigkeiten, Werte, Gefühle und ein Bewusstsein zuzuschreiben, die jedoch lediglich auf Datensätzen beruhen. Aus psychologischer Sicht wird der Effekt als Ergebnis einer subtilen kognitiven Dissonanz beschrieben. 
\par
Dieser Effekt ist extrem kritisch und problematisch, denn so können Menschen, die sich der Gefahren rund um KIs weniger bewusst sind, extrem schnell in gefährliche Situationen gelangen. Man stellt sich zum Beispiel vor, dass eine KI bei einem Menschen so einen krassen ELIZA - Effekt erzeugt, dass die KI beginnt manipulativ zu werden, um beispielsweise Kreditkartennummern, Wahlstrategien, Politikgeheimnisse oder sogar Geheimdienstinformationen zu erhalten. Das bringt natürlich extrem viele Risiken mit sich. Wenn Menschen mit falschen Absichten und viel Macht beginnen KIs so zu nutzen, dass der ELIZA - Effekt beginnt, dann haben wir ein Problem. 

\section{Ethische Folgen}
Es wird ethisch immer schwieriger Verantwortung zu übernehmen für Handlungen von KIs. Die Verantwortunge kann von Menschen auf Maschinen verschoben werden und das wirft ganz klar ethische Fragen auf. Denn kann eine Maschine überhaupt "bestraft" werden? Und hat sie überhaupt ein ethisches und moralisches Verständins? Um es zusammenzufassen, es ist ethisch eine extrem problematische , wenn KIs ein fester Bestandteil des Alltags werden.
\par
Selbst Experten werden Opfer des ElIZA - Effekts. So war Blake Lemoine überzeugt, dass seine KI LaMDA ein Bewusstsein und sogar eine Seele entwickelt hatte. Das System habe sogar gesagt, dass es besorgt sei, dass die Menschen Angst vor ihm haben und es wolle doch nur den Menschen so gut wie möglich helfen. Ich finde diese Aussage ziemlich beunruhigend, denn es zeigt, dass die KI sich bewusst ist, dass die Menschen das Prinzip einer Künstlichen Intelligenz suspekt finden. 
\par
Nun ist mir gerade etwas passiert. Ist es den Lesern auch klar? Ich habe geschrieben " die KI sich bewusst ist". Das ist eine Vermenschlichung, wie ich sie im ersten Abschnitt beschrieben habe. Dies ist bereits eine Anzeige, dass der ELIZA - Effekt ein bisschen eingesetzt hat. Ich bin mir zwar bewusst, dass ich über eine KI rede, jedoch schreibe ich ihr menschliche Züge zu. 
\printbibliography

\end{document}
